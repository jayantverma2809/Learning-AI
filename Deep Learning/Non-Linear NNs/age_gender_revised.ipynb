{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJeZUnDmwran"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71CoXULRw73J",
        "outputId": "b2f07cff-683c-4010-eff2-5d227e351d13"
      },
      "source": [
        "!kaggle datasets download -d jangedoo/utkface-new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading utkface-new.zip to /content\n",
            " 94% 313M/331M [00:20<00:01, 14.2MB/s]\n",
            "100% 331M/331M [00:20<00:00, 16.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt31O3rAw9zC"
      },
      "source": [
        "import zipfile\n",
        "zip = zipfile.ZipFile(\"/content/utkface-new.zip\",'r')\n",
        "zip.extractall(\"/content\")\n",
        "zip.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvru26NgyeiX"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLdaS9IGxI_u"
      },
      "source": [
        "folder_path = '/content/utkface_aligned_cropped/UTKFace'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Beh_PHKxuxM"
      },
      "source": [
        "age=[]\n",
        "gender=[]\n",
        "img_path=[]\n",
        "for file in os.listdir(folder_path):\n",
        "  age.append(int(file.split('_')[0]))\n",
        "  gender.append(int(file.split('_')[1]))\n",
        "  img_path.append(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxvpfqJIybDe",
        "outputId": "47492f21-ce70-40d5-b599-9d77c905868e"
      },
      "source": [
        "len(age)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14vOWlBAy9PR"
      },
      "source": [
        "df = pd.DataFrame({'age':age,'gender':gender,'img':img_path})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjD4tctdzNBJ",
        "outputId": "eb66d89d-0bbe-446b-c1e2-cf54be88819b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23708, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "M3OkWHlMzOYB",
        "outputId": "4271d5ce-623b-466e-d381-70f17bad0199"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>img</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1_1_3_20161219224454728.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>35_0_3_20170119201122781.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>35_0_0_20170117120747082.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>30_0_0_20170119180216577.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>30_1_2_20170104022925822.jpg.chip.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  gender                                    img\n",
              "0    1       1   1_1_3_20161219224454728.jpg.chip.jpg\n",
              "1   35       0  35_0_3_20170119201122781.jpg.chip.jpg\n",
              "2   35       0  35_0_0_20170117120747082.jpg.chip.jpg\n",
              "3   30       0  30_0_0_20170119180216577.jpg.chip.jpg\n",
              "4   30       1  30_1_2_20170104022925822.jpg.chip.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUEnfa9nzPlF"
      },
      "source": [
        "train_df = df.sample(frac=1,random_state=0).iloc[:20000]\n",
        "test_df = df.sample(frac=1,random_state=0).iloc[20000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OC_f8DUs3SWt",
        "outputId": "cda7920e-fa2f-44f7-befb-088743f43dc6"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VQFpZKf3UNQ",
        "outputId": "e61b3458-47e4-434e-c884-faf44a5b6ec9"
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3708, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RZCb0_Z3WNY"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=30,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_rMCGV94BwR",
        "outputId": "3411c841-4a82-4f9f-9c88-78d7d12759c2"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(train_df,\n",
        "                                                    directory=folder_path,\n",
        "                                                    x_col='img',\n",
        "                                                    y_col=['age','gender'],\n",
        "                                                    target_size=(200,200),\n",
        "                                                    class_mode='multi_output')\n",
        "\n",
        "test_generator = test_datagen.flow_from_dataframe(test_df,\n",
        "                                                    directory=folder_path,\n",
        "                                                    x_col='img',\n",
        "                                                    y_col=['age','gender'],\n",
        "                                                    target_size=(200,200),\n",
        "                                                  class_mode='multi_output')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 validated image filenames.\n",
            "Found 3708 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf7G1Xwg47La"
      },
      "source": [
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.layers import *\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFaEWJCL8CNk"
      },
      "source": [
        "resnet = ResNet50(include_top=False, input_shape=(200,200,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AoScqH980Ek"
      },
      "source": [
        "resnet = ResNet50(include_top=False, input_shape=(200,200,3))\n",
        "\n",
        "resnet.trainable=False\n",
        "\n",
        "output = resnet.layers[-1].output\n",
        "\n",
        "flatten = Flatten()(output)\n",
        "\n",
        "dense1 = Dense(512, activation='relu')(flatten)\n",
        "dense2 = Dense(512,activation='relu')(flatten)\n",
        "\n",
        "dense3 = Dense(512,activation='relu')(dense1)\n",
        "dense4 = Dense(512,activation='relu')(dense2)\n",
        "\n",
        "output1 = Dense(1,activation='linear',name='age')(dense3)\n",
        "output2 = Dense(1,activation='sigmoid',name='gender')(dense4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g_-is64JZdW"
      },
      "source": [
        "model = Model(inputs=resnet.input,outputs=[output1,output2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgdRuWd_Jdu_"
      },
      "source": [
        "model.compile(optimizer='adam', loss={'age': 'mae', 'gender': 'binary_crossentropy'}, metrics={'age': 'mae', 'gender': 'accuracy'},loss_weights={'age':1,'gender':99})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-K-t3f6Jgyj",
        "outputId": "c25dccde-e09a-4f3c-b47b-498e63578649"
      },
      "source": [
        "model.fit(train_generator, batch_size=32, epochs=10, validation_data=test_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 192s 308ms/step - loss: 99.9177 - age_loss: 15.4168 - gender_loss: 0.8535 - age_mae: 15.4168 - gender_accuracy: 0.5128 - val_loss: 83.2029 - val_age_loss: 14.7048 - val_gender_loss: 0.6919 - val_age_mae: 14.7048 - val_gender_accuracy: 0.5251\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 189s 302ms/step - loss: 83.7399 - age_loss: 15.1015 - gender_loss: 0.6933 - age_mae: 15.1015 - gender_accuracy: 0.5214 - val_loss: 144.5108 - val_age_loss: 14.6180 - val_gender_loss: 1.3120 - val_age_mae: 14.6180 - val_gender_accuracy: 0.5251\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 187s 299ms/step - loss: 84.2922 - age_loss: 14.9594 - gender_loss: 0.7003 - age_mae: 14.9594 - gender_accuracy: 0.5206 - val_loss: 83.4230 - val_age_loss: 14.9192 - val_gender_loss: 0.6920 - val_age_mae: 14.9192 - val_gender_accuracy: 0.5251\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 185s 296ms/step - loss: 83.5334 - age_loss: 14.8921 - gender_loss: 0.6933 - age_mae: 14.8921 - gender_accuracy: 0.5222 - val_loss: 83.0379 - val_age_loss: 14.5357 - val_gender_loss: 0.6919 - val_age_mae: 14.5357 - val_gender_accuracy: 0.5251\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 187s 300ms/step - loss: 83.8357 - age_loss: 14.7426 - gender_loss: 0.6979 - age_mae: 14.7426 - gender_accuracy: 0.5224 - val_loss: 83.0152 - val_age_loss: 14.5136 - val_gender_loss: 0.6919 - val_age_mae: 14.5136 - val_gender_accuracy: 0.5254\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 186s 298ms/step - loss: 83.5811 - age_loss: 14.7758 - gender_loss: 0.6950 - age_mae: 14.7758 - gender_accuracy: 0.5224 - val_loss: 82.7662 - val_age_loss: 14.2616 - val_gender_loss: 0.6920 - val_age_mae: 14.2616 - val_gender_accuracy: 0.5251\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 185s 296ms/step - loss: 83.2974 - age_loss: 14.6184 - gender_loss: 0.6937 - age_mae: 14.6184 - gender_accuracy: 0.5217 - val_loss: 82.6216 - val_age_loss: 14.1244 - val_gender_loss: 0.6919 - val_age_mae: 14.1244 - val_gender_accuracy: 0.5251\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 184s 295ms/step - loss: 83.3288 - age_loss: 14.6141 - gender_loss: 0.6941 - age_mae: 14.6141 - gender_accuracy: 0.5222 - val_loss: 82.4842 - val_age_loss: 13.9861 - val_gender_loss: 0.6919 - val_age_mae: 13.9861 - val_gender_accuracy: 0.5251\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 184s 295ms/step - loss: 83.0964 - age_loss: 14.5621 - gender_loss: 0.6923 - age_mae: 14.5621 - gender_accuracy: 0.5222 - val_loss: 82.4606 - val_age_loss: 13.9570 - val_gender_loss: 0.6920 - val_age_mae: 13.9570 - val_gender_accuracy: 0.5251\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 185s 295ms/step - loss: 83.0771 - age_loss: 14.4213 - gender_loss: 0.6935 - age_mae: 14.4213 - gender_accuracy: 0.5225 - val_loss: 82.3082 - val_age_loss: 13.7967 - val_gender_loss: 0.6920 - val_age_mae: 13.7967 - val_gender_accuracy: 0.5251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc952609390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTF0nIdjJinj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}