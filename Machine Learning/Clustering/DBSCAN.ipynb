{"cells":[{"cell_type":"markdown","metadata":{},"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["# **DBSCAN**\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is a base algorithm for density-based clustering.\n","\n","## Use cases of DBSCAN:\n","\n","- **Recommender systems** that make recommendations to users based on preferences (such as Netflix viewing patterns) of similar users (such as neighbors).\n","- **Anomaly detection** that identifies rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behavior.\n","- **Customer segmentation** that aims at separating customers into multiple clusters, and devise targeted marketing strategy based on each cluster's characteristics.\n"]},{"cell_type":"markdown","metadata":{},"source":["## When is DBSCAN better than K-Means?\n","\n","\n","You are a Data Scientist working for a retail company, and the marketing team wants you to use Data Science techniques to divide the company's customer base into groups of individuals that are similar in specific aspects such as age, gender, and spending behavior, so that they could devise targeted marketing strategy for each group based on its average spending on various product categories. \n","\n","In this case, since you don't know what would be the optimal number of groups/clusters to look for in the customer base, you can't use K-Means as it requires you to specify the number of clusters. \n","\n","Besides, since the marketing team wants to understand the average spendings of each group in order to devise its corresponding promotion, we should use an algorithm that's more robust to outliers.\n","\n","\u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/images/marketing.jpg\" style=\"width: 70%\"\u003e\n","\n","Image from [PxHere](https://pxhere.com/en/photo/1448601?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)\n"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook, we will look at a clustering technique using DBSCAN, which help us overcome the two aforementioned shortcomings of the K-Means clustering. Also, we will be able to look at the handwriting example to prove whether someones handwriting is bad, using DBSCAN.\n"]},{"cell_type":"markdown","metadata":{},"source":["## __Table of Contents__\n","\n","\u003col\u003e\n","    \u003cli\u003e\u003ca href=\"#Objectives\"\u003eObjectives\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\n","        \u003ca href=\"#Setup\"\u003eSetup\u003c/a\u003e\n","        \u003col\u003e\n","            \u003cli\u003e\u003ca href=\"#Installing-Required-Libraries\"\u003eInstalling Required Libraries\u003c/a\u003e\u003c/li\u003e\n","            \u003cli\u003e\u003ca href=\"#Importing-Required-Libraries\"\u003eImporting Required Libraries\u003c/a\u003e\u003c/li\u003e\n","        \u003c/ol\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\n","        \u003ca href=\"#Background\"\u003eBackground\u003c/a\u003e\n","        \u003col\u003e\n","            \u003cli\u003e\u003ca href=\"#How-does-DBSCAN-work?\"\u003eHow does DBSCAN work?\u003c/a\u003e\u003c/li\u003e\n","        \u003c/ol\u003e\n","    \u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Visual-Example\"\u003eExample 1: Visual Example\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Proving-Your-Friend-Has-Bad-Handwriting\"\u003eExample 2: Proving your friend has bad handwriting\u003c/a\u003e\u003c/li\u003e\n","\u003c/ol\u003e\n","\n","\u003ca href=\"#Exercises\"\u003eExercises\u003c/a\u003e\n","\u003col\u003e\n","    \u003cli\u003e\u003ca href=\"#Exercise-1---Find-the-number-of-clusters\"\u003eExercise 1 - Find the number of clusters\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Exercise-2---Find-the-%-of-data-marked-as-noise\"\u003eExercise 2 - Find the % of data marked as noise\u003c/a\u003e\u003c/li\u003e\n","    \u003cli\u003e\u003ca href=\"#Exercise-3---Visualize-the-clustered-data-using-matplotlib.pyplot\"\u003eExercise 3 - Visualize the clustered data using matplotlib.pyplot\u003c/a\u003e\u003c/li\u003e\n","\u003c/ol\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["----\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","metadata":{},"source":["* __Explain__ what DBSCAN does and how it works.\n","* __Understand__ the strengths, weaknesses, and use cases of DBSCAN.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Setup\n"]},{"cell_type":"markdown","metadata":{},"source":["For this lab, we will be using the following libraries:\n"," - [`pandas`](https://pandas.pydata.org/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for managing the data.\n"," - [`numpy`](https://numpy.org/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for mathematical operations.\n"," - [`matplotlib`](https://matplotlib.org/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for visualizing the data.\n"," - [`scipy`](https://docs.scipy.org/doc/scipy/reference/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for complex numerical operations.\n"," - [`sklearn`](https://scikit-learn.org/stable/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) for machine learning and machine-learning-pipeline related functions.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Installing Required Libraries\n","\n","The following required modules are pre-installed in the Skills Network Labs environment. However if you run this notebook commands in a different Jupyter environment (e.g. Watson Studio or Ananconda) you will need to install these libraries by removing the `#` sign before `!mamba` in the code cell below.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n","#!mamba install -qy pandas==1.3.4 numpy==1.21.4 matplotlib==3.5.0 scikit-learn==0.20.1 scipy==1.7.3\n","# Note: If your environment doesn't support \"!mamba install\", use \"!pip install pandas==1.3.4 ...\""]},{"cell_type":"markdown","metadata":{},"source":["### Importing Required Libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Surpress any warnings:\n","def warn(*args, **kwargs):\n","    pass\n","import warnings\n","warnings.warn = warn\n","import string\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.cluster import DBSCAN\n","from sklearn.manifold import TSNE\n","from sklearn.datasets import load_digits\n","\n","import seaborn as sns\n","\n","sns.set_context('notebook')\n","sns.set_style('white')\n","\n","# Import matplotlib for 3d plotting:\n","import matplotlib.pyplot as plt\n","\n","# Make matplotlib work in jupyter notebook\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["## Background\n","\n","__DBSCAN__ is a clustering algorithm that stands for:\n","\n","\"**D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise\"\n","\n"," - _Density-Based_ - DBSCAN will group points that are densely-packed together\n"," - _Spacial-Clustering_ - DBSCAN is for numerical points $\\in \\mathbb{R}^n$\n"," - _Applications with Noise_ - DBSCAN is great for applications that have noise\n","   - This is because DBSCAN also finds outliers/noise in data\n"]},{"cell_type":"markdown","metadata":{"tags":[]},"source":["### How does DBSCAN work?\n","\n","__DBSCAN__ uses two parameters:\n"," - `eps` (aka epsilon - $\\epsilon$) - the max distance between two points for them to be considered \"in the same neighborhood\"\n"," - `min_samples` - the minimum number of neighbors a point needs to be considered a __core point__.\n","\n","If a point is a neighbor of a __core point__, then it's in the same cluster as that point.\n","\n","Otherwise, it's considered to be __noise__.\n","\n","\n","#### Additional Resources\n","\n","You're encouraged to take a look at the [Pseudocode for DBSCAN](https://www.researchgate.net/figure/Pseudocode-of-the-DBSCAN-algorithm_fig2_325059373?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) if a more in-depth understanding is desired.\n","\n","[The original DBSCAN paper ](https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) hosted by [aaai.org](https://www.aaai.org/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01).\n"]},{"cell_type":"markdown","metadata":{},"source":["## Visual Example\n","\n","Let's begin with a visual example that demonstrates how DBSCAN works.\n","\n","Load the dataset `grid.csv` into a DataFrame:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/example1.csv')\n","df.head(n=6)"]},{"cell_type":"markdown","metadata":{},"source":["We can see the dataset is a small handful of points $3$ units apart:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']\n","plt.scatter(df['0'], df['1'])\n","for t, p in zip(string.ascii_uppercase, df.iterrows()):\n","    plt.annotate(t, (p[1][0] + 0.2, p[1][1]))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We apply the DBSCAN algorithm with:\n","\n"," - `eps=3` \n"," - `min_samples=4`\n","\n","Lets think about what should happen:\n","  - The point $C$ is the only point that has `min_samples=4` or more points within a distance of `eps=3`.\n","    - This makes $C$ the only __core__ point in the dataset.\n","  - Points $A$, $B$, $D$, and $E$ are within `eps=3` units from $C$.\n","    - This means $A$, $B$, $D$, and $E$ will be in the same cluster as $C$.\n","  - Finally, point $F$ is __not__ within `eps=3` units of a core point\n","    - $F$ will be labeled as **noise**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cluster = DBSCAN(eps=3, min_samples=4)\n","cluster.fit(df)\n","print(f'DBSCAN found {len(set(cluster.labels_) - set([-1]))} clusters and {(cluster.labels_ == -1).sum()} points of noise.')"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize how DBSCAN clustered our dataset:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']\n","plt.scatter(df['0'], df['1'], c=[['blue', 'red'][l] for l in cluster.labels_])\n","plt.scatter(0, 0, c='blue', alpha=0.2, s=90000)\n","plt.scatter(6, 0, c='red', alpha=0.2, s=9000)\n","for t, p in zip(string.ascii_uppercase, df.iterrows()):\n","    plt.annotate(t, (p[1][0] + 0.2, p[1][1]))\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["As expected, DBSCAN found one cluster (blue) and one point of noise (red).\n"]},{"cell_type":"markdown","metadata":{},"source":["## Proving Someone Has Bad Handwriting\n","\n","Let's say your friend has aweful handwriting.\n","You (as a good friend) want to help out, but:\n"," - _They will only work on their handwriting if you can prove their handwriting is bad._\n","\n","One way to do this is to cluster readable handwriting from other people using DBSCAN.\n","\n","The idea is: If your friend struggles to properly write a specific character, it will either:\n"," 1. Be marked as noise by `DBSCAN`.\n"," 2. Be grouped with a different kind of character\n","    - For example, if your friend wrote a \"5\" but it's grouped with \"4\"s, then it's probably not a very well-written 5.\n","\n","Our pipeline will be as follows:\n"," 1. Load and Scale the data.\n"," 2. Apply `TSNE` algorithm.\n","    - To overly simplify, `TSNE` reduces the dimension of data such that similar data is closer together.\n"," 3. Apply `DBSCAN` algorithm.\n"," 4. Visualize our categorized data and show how dissimilar our friend's handwriting is.\n"]},{"cell_type":"markdown","metadata":{},"source":["First, we handwritten data we gathered from our friend's math assignment:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/012.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize our data using `matplotlib`,\n","\n","We will need to reshape the data into 8x8 images, so matplotlib can properly display it:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["friend_digits = df.iloc[:, df.columns != 'y'].to_numpy()\n","plt.rcParams['figure.figsize'] = (8,6)\n","it = (x.reshape(8, 8) for x in friend_digits)\n","c = 3\n","fig, ax = plt.subplots(1, c, sharex='col', sharey='row')\n","for j in range(c):\n","    ax[j].axis('off')\n","    ax[j].set_title(f'Sample of friend\\'s number {j}')\n","    ax[j].imshow(next(it))\n","plt.show()\n","plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']"]},{"cell_type":"markdown","metadata":{},"source":["Next, we import the a dataset of digits from `sklearn` based on the MNIST dataset.\n","This data contains handwritten numbers from hundreds individuals across the United States:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the data\n","digits, y = load_digits(return_X_y=True)\n","pd.DataFrame(digits).head()"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize our data using `matplotlib`:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (8,6)\n","it = (x.reshape(8, 8) for x in digits)\n","r, c = 3, 5\n","fig, ax = plt.subplots(r, c, sharex='col', sharey='row')\n","for i in range(r):\n","    for j in range(c):\n","        ax[i, j].axis('off')\n","        ax[i, j].imshow(next(it))\n","plt.show()\n","plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']"]},{"cell_type":"markdown","metadata":{},"source":["Now we create the dataset for our pipeline, containing _both_ MNIST and our friend's digits:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Use np.r_ to concatenate two rows:\n","data = np.r_[digits, friend_digits]\n","y = np.r_[y, df['y']]"]},{"cell_type":"markdown","metadata":{},"source":["Next, we initialize the objects for our pipeline, with our chosen hyperparameters:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["embedding = TSNE(n_components=2,\n","        init=\"pca\",\n","        n_iter=500,\n","        n_iter_without_progress=150,\n","        perplexity=10,\n","        random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["e_data = embedding.fit_transform(data)"]},{"cell_type":"markdown","metadata":{},"source":["Our data after applying `TSNE` algorithm:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (20,15)\n","n = friend_digits.shape[0]\n","plt.scatter(\n","    e_data[:-n, 0],\n","    e_data[:-n, 1],\n","    marker='o',\n","    alpha=0.75,\n","    label='mnist data',\n","    s=100)\n","plt.scatter(\n","    e_data[-n:, 0],\n","    e_data[-n:, 1],\n","    marker='x',\n","    color='black',\n","    label='friend\\'s data',\n","    alpha=1,\n","    s=100)\n","plt.legend(bbox_to_anchor=[1, 1])\n","plt.show()\n","plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']"]},{"cell_type":"markdown","metadata":{},"source":["Next, we apply DBSCAN, using our chosen hyperparameters:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cluster = DBSCAN(eps=5, min_samples=20)\n","cluster.fit(e_data)\n","print(f'DBSCAN found {len(set(cluster.labels_) - set([-1]))} clusters and {(cluster.labels_ == -1).sum()} points of noise.')"]},{"cell_type":"markdown","metadata":{},"source":["Let's visualize our data again, categorized by DBSCAN:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.rcParams['figure.figsize'] = (20,15)\n","unique_labels = set(cluster.labels_)\n","n_labels = len(unique_labels)\n","cmap = plt.cm.get_cmap('brg', n_labels)\n","for l in unique_labels:\n","    plt.scatter(\n","        e_data[cluster.labels_ == l, 0],\n","        e_data[cluster.labels_ == l, 1],\n","        c=[cmap(l) if l \u003e= 0 else 'Black'],\n","        marker='ov'[l%2],\n","        alpha=0.75,\n","        s=100,\n","        label=f'Cluster {l}' if l \u003e= 0 else 'Noise')\n","plt.legend(bbox_to_anchor=[1, 1])\n","plt.show()\n","plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"The predicted labels of our friend's handwriting:\")\n","print(cluster.labels_[-3:])"]},{"cell_type":"markdown","metadata":{},"source":["Let's see how our pipeline categorized some of the data in its original, handwritten form:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["r, c = 1, 5\n","plt.rcParams['figure.figsize'] = (4*r,4*c)\n","for label in unique_labels:\n","    cluster_data = data[cluster.labels_ == label]\n","    nums = cluster_data[np.random.choice(len(cluster_data), r * c, replace=False)]\n","    it = (x.reshape(8, 8) for x in nums)\n","    fig, ax = plt.subplots(r, c)\n","    ax = ax.reshape(r, c)\n","    plt.subplots_adjust(wspace=0.1, hspace=-0.69)\n","    fig.suptitle(f'Original data from cluster {label}', fontsize=20, y=0.545)\n","    for i in range(r):\n","        for j in range(c):\n","            ax[i, j].axis('off')\n","            ax[i, j].imshow(next(it))\n","plt.show()\n","plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']"]},{"cell_type":"markdown","metadata":{},"source":["In this case we do have the original labels,\n","\n","Let's compare `DBSCAN`'s clusters to the actual labels:\n"]},{"cell_type":"code","execution_count":null,"metadata":{"tags":[]},"outputs":[],"source":["print('Correct labels:')\n","plt.rcParams['figure.figsize'] = (20,15)\n","\n","unique_labels = set(y)\n","n_labels = len(unique_labels)\n","cmap = plt.cm.get_cmap('brg', n_labels)\n","for l in unique_labels:\n","    plt.scatter(\n","        e_data[y == l, 0],\n","        e_data[y == l, 1],\n","        c=[cmap(l)],\n","        marker=f'${l}$',\n","        alpha=1,\n","        label=f'{l}',\n","        s=100)\n","plt.legend(bbox_to_anchor=[1, 1])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we can prove our friend's handwriting is unreadable (even for state-of-the-art unsupervised algorithms):\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for i, (l, t) in enumerate(zip(cluster.labels_[-3:], y[-3:])):\n","    print('-' * 30)\n","    print(f'Your friend\\'s {i}th sample was categorized as being in cluster #{l}')\n","    if l == -1:\n","        print('(IE: Noise)')\n","    else:\n","        v, c = np.unique(y[cluster.labels_ == l], return_counts=True)\n","        mfreq = v[np.argmax(c)]\n","        ratio = c.max() / c.sum()\n","        print(f'Cluster {l} is {ratio * 100:.2f}% the number {mfreq}')\n","        \n","    print(f'Your friend\\'s {i}th sample is supposed to be the number {t}')"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, all our friend's data was either categorized as noise, or put in a category where the vast majority is a different number.\n"]},{"cell_type":"markdown","metadata":{},"source":["# Exercises\n","\n","In this section, you can practice using `DBSCAN` by applying the algorithm on different datasets.\n","\n","Please run the following code to acquire the dataset for the exercises:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pd.read_csv('https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML0187EN-SkillsNetwork/labs/module%202/data/DBSCAN_exercises.csv')\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["Here's what the data looks like:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.scatter(df['x'], df['y'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 1 - Find the number of clusters\n","\n","Find the number of clusters with:\n","   - `eps=2`\n","   - `min_samples=10`\n","\n","(Not including noise).\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick Here For a Sample Solution\u003c/summary\u003e\n","    \n","```python\n","cluster = DBSCAN(eps=4, min_samples=4)\n","cluster.fit(df)\n","print(len(set(cluster.labels_) - {1}))\n","```\n","\n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 2 - Find the % of data marked as noise\n","\n","Using the fitted `DBSCAN` object from the previous exercise, find % of the data that was marked as noise:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick Here For a Sample Solution\u003c/summary\u003e\n","    \n","```python\n","print(f'{100 * (cluster.labels_ == -1).sum() / len(cluster.labels_)}%')\n","```\n","    \n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["## Exercise 3 - Visualize the clustered data using matplotlib.pyplot\n","\n","It's very useful to visualize your clustered data when possible (i.e., when dimension is low enough);\n","\n","Using `matplotlib.pyplot`, visualize the clustered data - where each cluster has its own assigned color.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# TODO\n"]},{"cell_type":"markdown","metadata":{},"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick Here For a Sample Solution\u003c/summary\u003e\n","    \n","```python\n","plt.rcParams['figure.figsize'] = (20,15)\n","unique_labels = set(cluster.labels_)\n","n_labels = len(unique_labels)\n","cmap = plt.cm.get_cmap('brg', n_labels)\n","for l in unique_labels:\n","    plt.scatter(\n","        df['x'][cluster.labels_ == l],\n","        df['y'][cluster.labels_ == l],\n","        c=[cmap(l)],\n","        marker='ov'[l%2],\n","        alpha=0.75,\n","        s=100,\n","        label=f'Cluster {l}' if l \u003e= 0 else 'Noise')\n","plt.legend(bbox_to_anchor=[1, 1])\n","plt.show()\n","plt.rcParams['figure.figsize'] = plt.rcParamsDefault['figure.figsize']\n","```\n","    \n","\u003c/details\u003e\n"]},{"cell_type":"markdown","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","metadata":{},"source":["[Sam Prokopchuk](https://www.linkedin.com/in/sam-prokopchuk-1908b21a0/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Other Contributors\n"]},{"cell_type":"markdown","metadata":{},"source":["[Roxanne Li](https://www.linkedin.com/in/roxanne-li/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0187ENSkillsNetwork821-2023-01-01) is a Data Science intern at IBM Skills Network, entering level-5 study in the Mathematics \u0026 Statistics undergraduate Coop program at McMaster University.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2021-12-20|0.1|Sam Prokopchuk|Complete Exercises' content|\n","|2022-05-20|0.2|Roxanne Li|Review and edit|\n","|2022-07-18|0.2|Svitlana K |Review and edit|\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright Â© 2021 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}